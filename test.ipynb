{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集形状: (124, 19)\n",
      "训练标签形状: (124, 2)\n",
      "测试数据集形状: (31, 19)\n"
     ]
    }
   ],
   "source": [
    "import image_process_copy\n",
    "\n",
    "# 加载hepatitis数据集\n",
    "train_data, train_labels, test_data, test_labels = image_process_copy.load_and_preprocess_hepatitis(test_size=0.2, shuffle=True, normalize=False)\n",
    "\n",
    "# 打印数据集的形状\n",
    "print(\"训练数据集形状:\", train_data.shape)\n",
    "print(\"训练标签形状:\", train_labels.shape)\n",
    "print(\"测试数据集形状:\", test_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30.    0.    0.  ...   3.9 100.    1. ]\n",
      " [ 42.    0.    1.  ...   4.  100.    1. ]\n",
      " [ 30.    0.    0.  ...   4.  100.    0. ]\n",
      " ...\n",
      " [ 47.    0.    0.  ...   4.  100.    0. ]\n",
      " [ 33.    0.    1.  ...   4.  100.    1. ]\n",
      " [ 27.    0.    0.  ...   3.   66.    1. ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0列的最小值为7.0,最大值为78.0\n",
      "第1列的最小值为0.0,最大值为1.0\n",
      "第2列的最小值为0.0,最大值为1.0\n",
      "第3列的最小值为0.0,最大值为1.0\n",
      "第4列的最小值为0.0,最大值为1.0\n",
      "第5列的最小值为0.0,最大值为1.0\n",
      "第6列的最小值为0.0,最大值为1.0\n",
      "第7列的最小值为0.0,最大值为1.0\n",
      "第8列的最小值为0.0,最大值为1.0\n",
      "第9列的最小值为0.0,最大值为1.0\n",
      "第10列的最小值为0.0,最大值为1.0\n",
      "第11列的最小值为0.0,最大值为1.0\n",
      "第12列的最小值为0.0,最大值为1.0\n",
      "第13列的最小值为0.3,最大值为7.6\n",
      "第14列的最小值为30.0,最大值为295.0\n",
      "第15列的最小值为14.0,最大值为648.0\n",
      "第16列的最小值为2.1,最大值为6.4\n",
      "第17列的最小值为0.0,最大值为100.0\n",
      "第18列的最小值为0.0,最大值为1.0\n",
      "归一化后的训练数据范围: 0.0 - 1.0\n",
      "归一化后的测试数据范围: 0.0 - 528.0\n"
     ]
    }
   ],
   "source": [
    "# 对训练数据的每个特征维度进行标准化到[0,1]区间\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用UMAP将数据从784维降至50维...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramIDE\\Anaconda\\envs\\torch121\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\ProgramIDE\\Anaconda\\envs\\torch121\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP拟合训练数据耗时: 81.63秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramIDE\\Anaconda\\envs\\torch121\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP转换测试数据耗时: 11.02秒\n",
      "降维后的数据形状: 训练数据 (60000, 50), 测试数据 (10000, 50)\n"
     ]
    }
   ],
   "source": [
    "from mnist_train import *\n",
    "\n",
    "train_data, train_label, test_data, test_label = load_data('mnist')\n",
    "# 进行UMAP降维  \n",
    "n_components = 10\n",
    "n_neighbors = 15\n",
    "min_dist = 0.1\n",
    "\n",
    "preprocess_data_path = './preprocess_data'\n",
    "if not os.path.exists(preprocess_data_path):\n",
    "    os.makedirs(preprocess_data_path)\n",
    "\n",
    "for n_components in range(10, 50, 10):\n",
    "    for n_neighbors in range(5, 30, 5):\n",
    "        for min_dist in range(0.001, 0.1, 0.002):\n",
    "            train_data_umap, test_data_umap, umap_reducer = apply_umap_preprocessing(train_data, test_data,\n",
    "                                                  \n",
    "                                                                        # 选择较好的UMAP参数组合\n",
    "                                                                        # n_components: 降维后的维度，2维便于可视化\n",
    "                                                                        # n_neighbors: 较大值(15-50)保留全局结构，较小值(5-15)保留局部结构\n",
    "                                                                        # min_dist: 较小值(0.001-0.1)使聚类更紧密，较大值(0.5-0.8)使分布更均匀\n",
    "                                                                        n_components=n_components, \n",
    "                                                                        n_neighbors=n_neighbors,  # 增大以更好地保留全局结构\n",
    "                                                                        min_dist=min_dist)   # 调小以使聚类更紧密\n",
    "            \n",
    "            # 保存拟合之后的数据\n",
    "            np.save(f'{preprocess_data_path}/mnist_train_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy', train_data_umap)\n",
    "            np.save(f'{preprocess_data_path}/mnist_test_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy', test_data_umap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "preprocess_data_path = './preprocess_data'\n",
    "if not os.path.exists(preprocess_data_path):\n",
    "    os.makedirs(preprocess_data_path)\n",
    "\n",
    "# 保存拟合之后的数据\n",
    "np.save(f'{preprocess_data_path}/mnist_train_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy', train_data_umap)\n",
    "np.save(f'{preprocess_data_path}/mnist_test_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy', test_data_umap)\n",
    "# 加载拟合之后的数据\n",
    "train_data_umap = np.load(f'{preprocess_data_path}/mnist_train_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy')\n",
    "test_data_umap = np.load(f'{preprocess_data_path}/mnist_test_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_data_train = np.load(f'{preprocess_data_path}/mnist_train_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy')\n",
    "umap_data_test = np.load(f'{preprocess_data_path}/mnist_test_data_umap_{n_components}_{n_neighbors}_{min_dist}.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
